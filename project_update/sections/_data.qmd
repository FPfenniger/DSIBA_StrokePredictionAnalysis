# Data

## Sources

The data utilized for this project originates from the Stroke Prediction Dataset available on Kaggle, which is a public platform that hosts a variety of datasets curated by data scientists and researchers. This specific dataset includes health-related variables that are relevant for predicting the likelihood of a stroke based on features like age, gender, and medical history. Sadly, we do not have more information on how the data was collected. The source is confidential and the use of it is only for educational purposes.

## Description

The data contains 5110 observations with 12 attributes. Here's summary of the main features of the dataset:

1.  id:

-   Type: Numerical (Continous)
-   Description: A unique identifier for each patient in the dataset.

2.  gender:

-   Type: Categorical
-   Values: "Male", "Female", or "Other"
-   Description: Gender of the patient

3.  age:

-   Type: Numerical (Continuous)
-   Description: Age of the patient

4.  hypertension:

-   Type: Categorical (Binary)
-   Values: 0 (No), 1 (Yes)
-   Description: Indicates whether the patient has hypertension.

5.  heart_disease:

-   Type: Categorical (Binary)
-   Values: 0 (No), 1 (Yes)
-   Description: Indicates whether the patient has heart disease

6.  ever_married:

-   Type: Categorical
-   Values: "No" or "Yes"
-   Description: Indicates whether the patient has ever been married

7.  work_type:

-   Type: Categorical
-   Values: "children", "Govt_job", "Never_worked", "Private", "Self-employed"
-   Description: Type of work the patient is engaged in

8.  Residence_type:

-   Type: Categorical
-   Values: "Rural" or "Urban"
-   Description: Indicates the living area of the patient

9.  avg_glucose_level:

-   Type: Numerical (Continuous)
-   Description: Average glucose level in the blood

10. bmi:

-   Type: Numerical (Continuous)
-   Description: Body Mass Index, a measure of body fat based on height and weight

11. smoking_status:

-   Type: Categorical
-   Values: "formerly smoked", "never smoked", "smokes", "Unknown"
-   Description: Indicates the smoking habits of the patient, where "Unknown" signifies that the smoking status information is not available.

12. stroke:

-   Type: Categorical (Binary)
-   Values: 0 (No), 1 (Yes)
-   Description: The target variable indicating whether the patient has had a stroke.

```{r, warning=FALSE}
#|code-fold: true 
#|code-summary: "Click to show code"
stroke_tb <- read.csv("../../data/stroke_dataset.csv") 
stroke_tb
```

Relevant metadata: Name of the owner of the dataset: Federico Soriano Palacios (found thanks to the link to his LinkedIn on his Kaggle profile) Last updated 4 years go (seen on Kaggle)

## Wrangling/Preprocessing

The dataset is fairly clean. Our dataset contains several categorical variables. Since a machine learning model requires numerical inputs, distinguished from the beginning categorical and numerical variables.

```{r, warning=FALSE}
#|code-fold: true
#|code-summary: "Click to show code"

# identify categorical and numerical variables
categorical_variables <- names(stroke_tb)[sapply(stroke_tb, function(x) is.character(x) || is.integer(x))]
numerical_variables <- names(stroke_tb)[sapply(stroke_tb, is.double)]

# print
cat(sprintf("Categorical features: %s\nNumerical features: %s",
            paste(categorical_variables, collapse = ", "),
            paste(numerical_variables, collapse = ", ")))
```
Secondly, we addressed missing values in the features “bmi” and “smoking_status” by replacing them with N/A. Additionally, we ensured that “bmi” is recognized as a numerical variable and updated the lists of categorical and numerical columns, as “bmi” is now a double. The id column has also been removed, as it is not relevant for our analysis moving forward.

```{r, warning=FALSE}
#|code-fold: true
#|code-summary: "Click to show code"
library(naniar)

cleaned_stroke_tb <- replace_with_na(data = stroke_tb, 
                                     replace = list(bmi = c("N/A"), smoking_status = c("Unknown"))) %>%
  mutate(bmi = as.numeric(bmi)) %>%
  select(-id)

cleaned_stroke_tb

# Selecting categorical variables (character or factor types)
categorical_variables <- names(cleaned_stroke_tb)[sapply(cleaned_stroke_tb, function(x) is.character(x) || is.integer(x))]
numerical_variables <- names(cleaned_stroke_tb)[sapply(cleaned_stroke_tb, is.double)]


# Use sprintf to format the message, then cat to print it with line breaks
cat(sprintf("Categorical features: %s\nNumerical features: %s",
            paste(categorical_variables, collapse = ", "),
            paste(numerical_variables, collapse = ", ")))
```

Then, to maintain the number of observations in our dataset, we replaced the N/A values in “bmi” with the median and in “smoking_status” with the modal value.

```{r, warning=FALSE}
#|code-fold: true
#|code-summary: "Click to show code"

# Calculate the median for bmi and the mode for smoking_status
bmi_median <- median(cleaned_stroke_tb$bmi, na.rm = TRUE)
smoking_status_mode <- names(which.max(table(cleaned_stroke_tb$smoking_status, useNA = "no")))

# Create preprocessed data by replacing NA values
preprocessed_stroke_tb <- cleaned_stroke_tb %>%
  mutate(
    bmi = ifelse(is.na(bmi), bmi_median, bmi),
    smoking_status = ifelse(is.na(smoking_status), smoking_status_mode, smoking_status)
  )

preprocessed_stroke_tb
```

For the categorical feature encoding, we have converted our categorical variables into dummy variables to utilize them in our predictive model.

```{r, warning=FALSE}
#|code-fold: true
#|code-summary: "Click to show code"
library(fastDummies)

encoded_stroke_tb <- dummy_cols(preprocessed_stroke_tb, select_columns=categorical_variables_1, remove_selected_columns = TRUE)

encoded_stroke_tb
```

Finally, as classification algorithms are often sensitive to scales and to prevent perturbations, we standardized all continuous features in the dataset.

```{r, warning=FALSE}
#|code-fold: true
#|code-summary: "Click to show code"
scaled_stroke_tb <- encoded_stroke_tb

#Scale only the double columns

scaled_stroke_tb[sapply(scaled_stroke_tb, is.double)] <- lapply(scaled_stroke_tb[sapply(scaled_stroke_tb, is.double)], scale)

scaled_stroke_tb <- as_tibble(scaled_stroke_tb)

scaled_stroke_tb
```

## Spotting Mistakes and Missing Data

Only the features `bmi` and `smoking_status` have missing values. As described previously, we replaced these missing values by N/A and replaced them in “bmi” with the median and in “smoking_status” with the modal value. Additionally, `bmi` had been imported as a character, so we converted it to a numeric variable. The `id` column was also removed as it was not relevant for our analysis.

## Listing Anomalies and Outliers

Upon examining the encoded stroke dataset for the categorical variables, we noticed that there is only three non-binary quantitative variables: age, average glucose level, and bmi. To visualize outliers in each of these variables, we used boxplots. The points outside the range defined by the whiskers were identified as outliers.

```{r, warning=FALSE}
#|code-fold: true
#|code-summary: "Click to show code"

# Boxplot for Age
boxplot(encoded_stroke_tb$age, main="Boxplot of Age", ylab="Age", col="lightblue")

# Boxplot for Average Glucose Level
boxplot(encoded_stroke_tb$avg_glucose_level, main="Boxplot of Average Glucose Level", ylab="Average Glucose Level", col="lightgreen")

# Boxplot for BMI
boxplot(encoded_stroke_tb$bmi, main="Boxplot of BMI", ylab="BMI", col="lightcoral")

#We use the IQR method to identify outliers
identify_outliers <- function(column) {
  Q1 <- quantile(column, 0.25)
  Q3 <- quantile(column, 0.75)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  
  # Identify Outliers
  outliers <- column[column < lower_bound | column > upper_bound]
  return(outliers)
}

# Apply the function to the variables
outliers_age <- identify_outliers(encoded_stroke_tb$age)
outliers_glucose <- identify_outliers(encoded_stroke_tb$avg_glucose_level)
outliers_bmi <- identify_outliers(encoded_stroke_tb$bmi)

#We create a function count_outliers that we will use to identify and count outliers in each non-binary quantitative variable 
  count_outliers <- function(column) {
  Q1 <- quantile(column, 0.25, na.rm = TRUE)
  Q3 <- quantile(column, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  
# Count outliers
outlier_count <- sum(column < lower_bound | column > upper_bound, na.rm = TRUE)
  return(outlier_count)
}

# Create a vector to hold the outlier counts
outlier_counts <- sapply(encoded_stroke_tb[, c("age", "avg_glucose_level", "bmi")], count_outliers)
outlier_counts

```
Finding zero outliers for `age` indicates a nearly normal distribution among the individuals in our population. With a dataset containing 5,110 rows, the identification of 627 outliers for `average_glucose_levels`, representing approximately 12.25% of the total population, and 126 outliers for Body Mass Index, constituting about 2.47%, highlighted disparities in the distribution of these health metrics. Both boxplots display a considerable number of outliers in the higher range, indicating that there are subsets of individuals in the dataset with unusually high average glucose levels and BMI values. These outliers could be due to a variety of factors, such as lifestyle, health conditions, or measurement errors. Considering their importance as risk factors, we decided to keep them in the dataset for now. However, we may revisit this decision later in the analysis, especially as we didn't examine the distributions in the upsampled dataset yet. 

After conducting the analysis of the numerical variables, we examined the distribution of the categorical variables.

Two distribution graphs captured our attention: the one for the `gender` category `Other` and the one for the `work_type` `Never worked`. The former appears only once in the dataset, while the latter appears just 22 times out of a total of 5,110 observations. Due to their extreme underrepresentation, we decided to exclude these variables from our analysis as they add unnecessary complexity.

```{r, warning=FALSE}
#|code-fold: true
#|code-summary: "Click to show code"
# Distribution of Gender Other
table(encoded_stroke_tb$gender_Other)
ggplot(encoded_stroke_tb, aes(x=factor(gender_Other))) + 
  geom_bar() + 
  labs(x='1 if gender is Other, 0 if not', y='Count', title='Distribution of Other gender')

#Count of Gender Other
count_other_gender <- sum(encoded_stroke_tb$gender_Other)
count_other_gender

# Distribution of Work Type is Never worked
table(encoded_stroke_tb$work_type_Never_worked)
ggplot(encoded_stroke_tb, aes(x=factor(work_type_Never_worked))) + 
  geom_bar() + 
  labs(x='1 if Work Type is Never Worked, 0 if not', y='Count', title='Distribution of Work Type is Never worked')

#Count of Work Type is Never worked
count_work_type_Never_worked <- sum(encoded_stroke_tb$work_type_Never_worked)
count_work_type_Never_worked
```
Finally, the dataset shows that most individuals do not have strokes. However, such an imbalance can negatively impact model performance, as models may become biased towards the majority class, leading to poor prediction accuracy for minority cases, such as strokes. If don't apply upsampling here, the accuracy of a naive model predicting always "no stroke" would probably significantly higher than our developed prediction model

```{r, warning=FALSE}
#|code-fold: true
#|code-summary: "Click to show the code"

# Distribution of strokes vs no strokes in the sample
table(encoded_stroke_tb$stroke)
ggplot(encoded_stroke_tb, aes(x=factor(`stroke`))) + 
  geom_bar() + 
  labs(x='0 no strokes, 1 strokes', y='Count', title='Distribution of strokes')


# count how many people had a stroke and the prop
encoded_stroke_tb %>%
  group_by(stroke) %>%
  summarize(count = n()) %>%
  mutate(proportion = round(count / sum(count), 2))
```
To address this, we used dataset balancing techniques to adjust the proportions of stroke and no-stroke cases. Since the dataset contains only 5,110 individuals, we have chosen to up-sample the minority class to avoid losing valuable data that could be discarded in down-sampling. By up-sampling, we can enhance the representation of stroke cases, which helps the model learn more effectively and improve prediction accuracy for both classes.

```{r, warning=FALSE}
#|code-fold: true
#|code-summary: "Click to show the code"

# Use upSample to balance the dataset
balanced_stroke_tb <- upSample(x = encoded_stroke_tb[, names(encoded_stroke_tb) != "stroke"],
                               y = encoded_stroke_tb$stroke,
                               yname = "stroke")

# Check the distribution to confirm balancing
table(balanced_stroke_tb$stroke)
```

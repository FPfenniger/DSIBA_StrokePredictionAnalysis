---
title: "Stroke_Prediction_Analysis_Group_C"
format: html
editor: visual
---

## 1. Introduction and Data Structure

### 1.1 Overview & Motivation

### 1.2 Related Work

### 1.3 Research Questions

### 1.4 Data Source

### 1.5 Data Import

```{r}
library(tidyverse)
library(knitr)
library(naniar)
```

You can add options to executable code like this

```{r}
#import of the dataset
stroke_db <- read.csv("data/stroke_dataset.csv")

#saving as a tibble
stroke_tb <- as_tibble(stroke_db)
head(stroke_tb)
```

In total, there are 12 variables including our binary target variable `stroke`.

## 2. Data Cleaning & Wrangeling

### 2.1 Data Exploration

Let's get a feeling for the distribution of our data:

```{r}
# Generate summary of your data frame
summary_table <- summary(stroke_tb)

# Convert the summary to a data frame & display it with kable
summary_table <- as.data.frame.matrix(summary_table)
kable(as.data.frame(summary_table), row.names = FALSE)

```

Our Dataset has a few categorical variables. As a machine learning model needs numerical inputs, we need to convert and encode them later. Let's create a list of categorical and numerical columns:

```{r}

categorical_variables <- names(stroke_tb)[sapply(stroke_tb,is.character)]
numerical_variables <- names(stroke_tb)[sapply(stroke_tb, is.numeric)]

# Use sprintf to format the message, then cat to print it with line breaks
cat(sprintf("Categorical features: %s\nNumerical features: %s",
            paste(categorical_variables, collapse = ", "),
            paste(numerical_variables, collapse = ", ")))
```

### 2.2 Missing Values

Let's look specifically at the missing values in our dataset:

```{r}
stroke_tb %>%
  summarize_all(~ sum(is.na(.) | . %in% c("N/A", "Unknown", "-")))
```

The dataset is fairly clean. Only the the features `bmi` and `smoking_status` have missing values. Let's change all missing values to N/A and ensure that `bmi` is recognized as a numerical variable. Additionally, the `id` column will be removed, because it is of no use for the future.

```{r}
cleaned_stroke_tb <- replace_with_na(data = stroke_tb, 
                                     replace = list(bmi = c("N/A"), smoking_status = c("Unknown"))) %>%
  mutate(bmi = as.numeric(bmi)) %>%
  select(-id)

cleaned_stroke_tb
```

We update the lists of categorical and numerical columns, as \`bmi\` is now a double.

```{r}
categorical_variables <- names(cleaned_stroke_tb)[sapply(cleaned_stroke_tb,is.character)]
numerical_variables <- names(cleaned_stroke_tb)[sapply(cleaned_stroke_tb, is.numeric)]

# Use sprintf to format the message, then cat to print it with line breaks
cat(sprintf("Categorical features: %s\nNumerical features: %s",
            paste(categorical_variables, collapse = ", "),
            paste(numerical_variables, collapse = ", ")))
```

As we would like to keep as many observations as possible in our dataset, we replace the N/As with the median for `bmi` and the modal value for `smoking_status`.

```{r}
# Calculate the median for bmi and the mode for smoking_status
bmi_median <- median(cleaned_stroke_tb$bmi, na.rm = TRUE)
smoking_status_mode <- names(which.max(table(cleaned_stroke_tb$smoking_status, useNA = "no")))

# Create preprocessed data by replacing NA values
preprocessed_stroke_tb <- cleaned_stroke_tb %>%
  mutate(
    bmi = ifelse(is.na(bmi), bmi_median, bmi),
    smoking_status = ifelse(is.na(smoking_status), smoking_status_mode, smoking_status)
  )

preprocessed_stroke_tb
```

### 2.3 Categorical Feature Encoding

To make use of our categorical variables in our predictive model, we need to convert them into dummy variables. We use the \`fastDummies\` package for the One Hot Encoding.

```{r}
library(fastDummies)

encoded_stroke_tb <- dummy_cols(preprocessed_stroke_tb, select_columns=categorical_variables, remove_selected_columns = TRUE)

encoded_stroke_tb
```

Multicollinearity between the different features will be a problem for our model. It will be treated in the Correlation Analysis.

### 2.4 Feature Scaling

Classification algorithms are often sensitive to scales. To prevent perturbations we standardize all continuous features in the dataset.

```{r}
scaled_stroke_tb <- encoded_stroke_tb

# Scale only the double columns
scaled_stroke_tb[sapply(scaled_stroke_tb, is.double)] <- 
  lapply(scaled_stroke_tb[sapply(scaled_stroke_tb, is.double)], scale)

scaled_stroke_tb <- as_tibble(scaled_stroke_tb)

scaled_stroke_tb
```

### 2.5 Outlier Analysis

### 

### 2.6 Dataset Balancing

## 3. Exploratory Data Analysis

### 3.1 Descriptive Statistics

### 3.2 Data Visualization

### 3.3 Correlation Analysis

Multicollinearity

## 4. Predictive Model

## 5. Model Evaluation and Predictions

## 6. Conclusions

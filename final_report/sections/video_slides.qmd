---
title: "Understanding Stroke: A Data-Driven Approach"
subtitle: "Data Science in Business Analytics"
author: "Bolor Battaiwan, Fabio Pfenniger, Muhammed Hussein"
date: "2024-12-10"
format: 
  revealjs:
    self-contained: false
    monofont: DejaVu Sans Mono
    theme: default
    transition: slide
    slide-number: true
editor: visual
---

```{r, message= FALSE}
#| code-fold: true
#| code-summary: "Click to show code"
#| label: setup
#| echo: false

# loading all the necessary packages
library(tidyverse)
library(shiny)
library(plotly)
library(vcd)
library(naniar)
library(fastDummies)
library(caret)
library(knitr)
library(ggplot2)
library(dplyr)
library(janitor)
library(MLmetrics)  
library(pROC)
library(kableExtra)
```

```{r}
stroke_tb <- read.csv("../../data/datasets/stroke_dataset.csv")
preprocessed_stroke_tb <- read.csv("../../data/datasets/preprocessed_stroke_tb.csv")
outlier_stroke_tb <- read.csv("../../data/datasets/outlier_stroke_tb.csv")
cleaned_stroke_tb <- read.csv("../../data/datasets/cleaned_stroke_tb.csv")
encoded_stroke_tb <- read.csv("../../data/datasets/encoded_stroke_tb.csv")
balanced_stroke_tb <- read.csv("../../data/datasets/balanced_stroke_tb.csv")
high_risk_age_tb <- read.csv("../../data/datasets/high_risk_age_tb.csv")
low_risk_age_tb <- read.csv("../../data/datasets/low_risk_age_tb.csv")
over_60_data_tb <- read.csv("../../data/datasets/over_60_data_tb.csv")
scaled_low_risk_age_tb <- read.csv("../../data/datasets/scaled_low_risk_age_tb.csv")
under_60_data_tb <- read.csv("../../data/datasets/under_60_data_tb.csv")
```


# Stroke: A Global Health Emergency

## The Problem:

-   15M strokes/year (WHO): 5M deaths, 5M disabilities.
-   Stroke disrupts brain blood flow: caused by blockage or bleeding.

## Project Goals:

-   Predict stroke risk using data.
-   Analyze key factors like age, heart disease, & lifestyle.
-   Visualize insights for better understanding.

Key question: What factors best predict stroke, and how can we intervene?

# Dataset Overview

### Data Source

-   Origin: Found on Kaggle.com. Owned and last updated in 2020 by Federico Soriano Palacios.
-   Observations: 5110
-   Features: 11

### Key Variables

-   Target Variable: stroke (0 = No, 1 = Yes)
-   Demographics: gender, age, Residence_type
-   Health Metrics: hypertension, heart_disease, avg_glucose_level, bmi
-   Lifestyle: smoking_status, work_type, ever_married

## Dataset
```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

# Original Dataset
kable(head(stroke_tb))

```

# Data Preprocessing

## Status quo:

Dataset is fairly clean because - No duplicate rows - Missing values only in bmi and smoking_status

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"
kable(colSums(stroke_tb == "Unknown" | stroke_tb == "N/A" | stroke_tb == ""))
```

## Processed dataset:

**Variable Adjustments:**
- Reclassified:
  - `bmi` â†’ numerical
  - `hypertension`, `heart_disease` â†’ categorical
- Removed irrelevant column: `id`

**Handling Missing Values:**
- `bmi`: replaced missing values with **median**
- `smoking_status`: replaced missing values with **mode**

**Outlier Analysis:**
- Visualized outliers in: `age`, `avg_glucose_level`, `bmi`
- Outliers Identified:
  - `avg_glucose_level`: 12.25% of dataset (627 points)
  - `bmi`: 2.47% of dataset (126 points)
- Decision: **Retain outliers** for now, as they may be relevant risk factors


Categorical Variables:

-   Removed infrequent categories in gender (Other) and work_type (Never_worked).
-   Noted rare occurrences in heart_disease, hypertension, and stroke.

# Findings and Results

## Profile of Stroke Cases

From the initial EDA, we can observe that individuals are at more struck by stroke if

-   older than 60 years
-   avg_glucose_level above
-   have heart disease
-   are former or current smokers
-   have hypertension


Stroke cases are more frequent at higher glucose levels and in the age range of 60 to 80 years.

```{r, message = FALSE}
#| code-fold: true
#| code-summary: "Click to show code"
library(ggplot2)
library(plotly)

# Function to create the histogram as plotly object
create_histogram <- function(data, variable, stroke_variable, binwidth = 5, show_legend = FALSE) {
  # Extract the variable and stroke data
  original_data <- data[[variable]]
  stroke_data <- data[[stroke_variable]]
  
  # Calculate mean and standard deviation for reference lines
  mean_val <- mean(original_data, na.rm = TRUE)
  sd_val <- sd(original_data, na.rm = TRUE)
  
  # Combine data and stroke status into a data frame
  plot_data <- data.frame(data = original_data, stroke = factor(stroke_data, labels = c("No Stroke", "Stroke")))
  
  # Generate the ggplot object (temporary)
  p <- ggplot(plot_data, aes(x = data, fill = stroke)) +
    geom_histogram(binwidth = binwidth, color = "white", position = "stack") +
    labs(y = "Frequency", fill = "Stroke Status") +
    scale_fill_manual(values = c("No Stroke" = "#1f77b4", "Stroke" = "#ff7f0e")) +  # Set custom colors
    theme_minimal() +
    theme(axis.title.x = element_blank(), plot.title = element_text(hjust = 0.5))  # Center title
  
  # Convert to interactive Plotly plot
  p_plotly <- ggplotly(p) %>%
    layout(showlegend = show_legend)  # Set legend visibility
  
  return(p_plotly)
}

# Generate histograms for each variable separately without repeating legends
hist_age <- create_histogram(outlier_stroke_tb, "age", "stroke", binwidth = 5, show_legend = FALSE) %>%
  layout(title = "Distribution of Age", xaxis = list(title = "Age"), 
         yaxis = list(title = "Frequency"))

hist_glucose <- create_histogram(outlier_stroke_tb, "avg_glucose_level", "stroke", binwidth = 5, show_legend = FALSE) %>%
  layout(title = "Distribution of Average Glucose Level", xaxis = list(title = "Average Glucose Level"), 
         yaxis = list(title = "Frequency"))

hist_bmi <- create_histogram(outlier_stroke_tb, "bmi", "stroke", binwidth = 5, show_legend = FALSE) %>%
  layout(title = "Distribution of BMI", xaxis = list(title = "BMI"), 
         yaxis = list(title = "Frequency"))

# Combine all histograms into a single interactive plot with a main title
combined_histograms <- subplot(hist_age, hist_glucose, hist_bmi, nrows = 1, titleY = TRUE,
                               shareX = TRUE, shareY = TRUE) %>%
  layout(title = "Histograms of Numerical Variables by Stroke", showlegend = TRUE)  # Set main title with legend visible

# Display combined histogram
combined_histograms
```

## 
There exist weak positive relationships between age and stroke, and avg_glucose_level and stroke. No relationship between bmi and stroke.

```{r, message = FALSE}
#| code-fold: true
#| code-summary: "Click to show code"
library(knitr)

# Calculate correlation coefficients for each variable with stroke
cor_age <- cor(as.numeric(outlier_stroke_tb$age), as.numeric(outlier_stroke_tb$stroke), method = "pearson")
cor_glucose <- cor(as.numeric(outlier_stroke_tb$avg_glucose_level), as.numeric(outlier_stroke_tb$stroke), method = "pearson")
cor_bmi <- cor(as.numeric(outlier_stroke_tb$bmi), as.numeric(outlier_stroke_tb$stroke), method = "pearson")

# Create a correlation table
correlation_table <- data.frame(
  Variable = c("Age", "Average Glucose Level", "BMI"),
  Correlation_with_Stroke = round(c(cor_age, cor_glucose, cor_bmi), 2)
)

# Display the correlation table with kable
kable(correlation_table, caption = "Correlation Coefficients with Stroke")
```


```{r}
#| code-fold: true
#| code-summary: "Click to show code"

# Define choices for the variable selection, excluding Gender and Residence Type
x_variable_choices <- c("Smoking Status" = "smoking_status",
                        "Hypertension" = "hypertension", 
                        "Heart Disease" = "heart_disease")

# Create a filtered data frame based on all selected variables
filtered_data <- outlier_stroke_tb
# Remove "Other" for the gender variable
filtered_data <- filtered_data %>% filter(!(gender == "Other"))  # Simply check for 'Other' in gender

# Initialize an empty list to store plots
plots <- list()

# Loop through each categorical variable and create a bar chart
for (selected_variable in x_variable_choices) {
  
  # Get variable name
  variable_name <- names(x_variable_choices)[which(x_variable_choices == selected_variable)]
  
  if (variable_name %in% c("hypertension", "heart_disease")) {
    p <- ggplot(filtered_data, aes_string(x = selected_variable, fill = "as.factor(stroke)")) +
      geom_bar(position = "fill") +
      labs(title = paste("Distribution of Stroke by", variable_name),
           fill = "STROKE", y = "Ratio") +
      scale_x_continuous(breaks = c(0, 1), labels = c("No", "Yes")) +  # Custom x-axis for binary variables
      scale_fill_manual(values = c("0" = "#1f77b4", "1" = "#ff7f0e"))  # Set colors for no stroke and stroke
  } else {
    # For other categorical variables
    p <- ggplot(filtered_data, aes_string(x = selected_variable, fill = "as.factor(stroke)")) +
      geom_bar(position = "fill") +
      labs(title = paste("Distribution of Stroke by", variable_name),
           fill = "STROKE", y = "Ratio") +
      scale_fill_manual(values = c("0" = "#1f77b4", "1" = "#ff7f0e"))  # Set colors for no stroke and stroke
  }
  
  # Convert ggplot to an interactive plotly object and store it in the list
  plots[[variable_name]] <- ggplotly(p)
}
# Display all plots
for (plot in plots) {
  print(plot)  # You can use print to display each plot one after the other
}
```

```{r, message = FALSE}
#| code-fold: true
#| code-summary: "Click to show code"
# Select the numeric columns from your data
numeric_data <- outlier_stroke_tb[, c("age", "avg_glucose_level", "bmi")]

# Calculate the correlation matrix
correlation_matrix <- cor(numeric_data, use = "complete.obs")

# Convert the correlation matrix to a format that plotly can use (optional step)
heatmap_data <- as.data.frame(as.table(correlation_matrix))

# Plot the correlation matrix as a heatmap using plotly
plot_ly(
  x = colnames(correlation_matrix),
  y = rownames(correlation_matrix),
  z = correlation_matrix,
  type = "heatmap",
  colorscale = "Viridis"  # Corrected typo
) %>%
  layout(
    title = "Correlation Matrix Heatmap",
    xaxis = list(title = "", tickangle = 45),
    yaxis = list(title = "")
  )
```
# Balanced EDA

Changes compared to baseline and we expect these factors to be potential predictors.


# Predictive Modeling


## Final data preparations: 

- Feature Encoding
- Multicollinearity
- Dataset balancing
- Scaling

## Modeling

For the modeling part, we decided to split the analysis into four differents parts:
- Baseline Model 
- Balanced Baseline Model
- Low-Risk Age Model 
- High-Risk Age Model

Modeling Approach: 
- Train a logistic regression model for each dataset
- Test model performance on a shared test set
-  80% of the data for training and 20% for testing

We focus on the most successful prediction model: the balanced baseline model.


# Results: 2. Balanced Original Dataset


![](figures/2_Results.png)

## Improved Metrics
![](figures/2_Metrics.png)
-   Accuracy: 77.45% - Strikes a better balance between positive and negative classes.
-   Recall (Positive Class): 81.35% - Effectively identifies most true positives.
-   F1-Score: 78.29% - Indicates a good balance between precision and recall.
-   Specificity: 73.5% - Lower, suggesting some false positives.

![](figures/2_ROC.png)
![](figures/2_Odds_ratio.png)


# Results: 3. Low-Risk Age Group

## Objective: Build the first stratified model for the low-risk age group.

## Approach

-   Dataset Split: Divide the original dataset into training and test sets.
-   Preprocessing: Apply previously mentioned preprocessing steps to the training set.

![](figures/3_Results.png)
![](figures/2_Metrics.png)
![](figures/2_ROC.png)
![](figures/2_Odds_ratio.png)


# Results: 4. High-Risk Age Group

![](figures/4_Results.png)
![](figures/4_Metrics.png)
## Performance Metrics

-   Accuracy: 63.70% - Moderate performance overall.
-   Recall (Positive Class): 66.11% - Captures a fair portion of true positives.
-   Precision: 63.07% - About 63% of predicted positives are correct.
-   F1-Score: 64.56% - Reasonable balance between precision and recall.
-   Specificity: 61.30% - Low, leading to higher false-positive rates.



![](figures/2_ROC.png)
![](figures/2_Odds_ratio.png)
## Interpretation

-   Strength: Moderate ability to capture true positives.
-   Weakness: Struggles to distinguish between classes, with low specificity and accuracy.


# Conclusion


# Grading criteria:

Criteria (Max Points 20): Description

Content (4): Clear and comprehensive explanation of the project, its goals, and outcomes.

Organization (4): Logical flow of information, from introduction to conclusion.

Teamwork (4): Demonstration of collaboration and presentation dynamics (individual projects automatically earn full points).

Visuals (4): Well-designed and relevant slides or visual aids that effectively convey information.

Presentation Mechanics (4): Clear speaking, good video/audio quality, and adherence to time limits.

# Requirements:

Introduction: Briefly introduce your project goals and motivation.

Research Questions: What were the key research questions?

Data: Provide a high-level overview of your data sources and preprocessing.

Findings and Results: Highlight your key findings, insights, or model results.

Conclusion: Summarize your main takeaways and future potential directions.

Length: 7 minutes or less. The time limit will be strictly enforced. Content:

Tell your story well! Focus on delivering clear, concise, and engaging insights from your project. ðŸš€

# Remarks for presentation slides:

Lets not show results in the presentation that are not relevant. Aim remains to predict stroke.

---
title: "Understanding Stroke: A Data-Driven Approach"
subtitle: "Data Science in Business Analytics"
author: "Bolor Battaiwan, Fabio Pfenniger, Muhammed Hussein"
date: "2024-12-10"
format: 
  revealjs:
    self-contained: false
    monofont: DejaVu Sans Mono
    theme: default
    transition: slide
    slide-number: true
editor: visual
---

```{r, message= FALSE}
#| code-fold: true
#| code-summary: "Click to show code"
#| label: setup
#| echo: false

# loading all the necessary packages
library(tidyverse)
library(shiny)
library(plotly)
library(vcd)
library(naniar)
library(fastDummies)
library(caret)
library(knitr)
library(ggplot2)
library(dplyr)
library(janitor)
library(MLmetrics)  
library(pROC)
library(kableExtra)
```

```{r}
stroke_tb <- read.csv("../../data/datasets/stroke_dataset.csv")
preprocessed_stroke_tb <- read.csv("../../data/datasets/preprocessed_stroke_tb.csv")
outlier_stroke_tb <- read.csv("../../data/datasets/outlier_stroke_tb.csv")
cleaned_stroke_tb <- read.csv("../../data/datasets/cleaned_stroke_tb.csv")
encoded_stroke_tb <- read.csv("../../data/datasets/encoded_stroke_tb.csv")
balanced_stroke_tb <- read.csv("../../data/datasets/balanced_stroke_tb.csv")
high_risk_age_tb <- read.csv("../../data/datasets/high_risk_age_tb.csv")
low_risk_age_tb <- read.csv("../../data/datasets/low_risk_age_tb.csv")
over_60_data_tb <- read.csv("../../data/datasets/over_60_data_tb.csv")
scaled_low_risk_age_tb <- read.csv("../../data/datasets/scaled_low_risk_age_tb.csv")
under_60_data_tb <- read.csv("../../data/datasets/under_60_data_tb.csv")
```


# Stroke: A Global Health Emergency

## The Problem:

-   15M strokes/year (WHO): 5M deaths, 5M disabilities.
-   Stroke disrupts brain blood flow: caused by blockage or bleeding.

## Project Goals:

-   Predict stroke risk using data.
-   Analyze key factors like age, heart disease, & lifestyle.
-   Visualize insights for better understanding.

## Key Question: What factors best predict stroke, and how can we intervene?

# Dataset Overview

## Data Source

-   Origin: Found on Kaggle.com. Owned and last updated in 2020 by Federico Soriano Palacios.
-   Observations: 5110
-   Features: 11

## Key Variables

-   Target Variable: stroke (0 = No, 1 = Yes)
-   Demographics: gender, age, Residence_type
-   Health Metrics: hypertension, heart_disease, avg_glucose_level, bmi
-   Lifestyle: smoking_status, work_type, ever_married

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

# Original Dataset
kable(stroke_tb)

```

# Data Preprocessing

## Original dataset:

Dataset is fairly clean because - No duplicate rows - Missing values only in bmi and smoking_status

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"
colSums(stroke_tb == "Unknown" | stroke_tb == "N/A" | stroke_tb == "")
```

## Processed dataset:

Variable Adjustments:

-Reclassified variables: bmi → numerical; hypertension, heart_disease → categorical. - Removed irrelevant column: id.

Handling Missing Values:

-   Replaced missing values: bmi → median, smoking_status → mode.

Outlier Analysis:

-   Visualized outliers in age, avg_glucose_level, and bmi using boxplots.
-   Outliers Identified:
-   avg_glucose_level: 12.25% of dataset (627 points).
-   bmi: 2.47% of dataset(126 points).
-   Retained outliers for now due to potential relevance as risk factors.

```{r}
#| code-fold: true
#| code-summary: "Click to show code"
library(ggplot2)
library(plotly)

variables <- c("age", "avg_glucose_level", "bmi")

for (var in variables) {
  p <- ggplot(preprocessed_stroke_tb, aes_string(y = var)) +
    geom_boxplot(outlier.color = "red", outlier.size = 2) +
    labs(title = paste("Boxplot of", var), y = var, x = "") 
  
  # Convert to Plotly and apply partial_bundle to reduce size
  p_plotly <- ggplotly(p) %>% partial_bundle()
  print(p_plotly)
}
```

Categorical Variables:

-   Removed infrequent categories in gender (Other) and work_type (Never_worked).
-   Noted rare occurrences in heart_disease, hypertension, and stroke.

# Findings and Results

## Profile of Stroke Cases

From the initial EDA, we can observe that individuals are at more struck by stroke if

-   older than 60 years
-   avg_glucose_level above
-   have heart disease
-   are former or current smokers
-   have hypertension
-   are married
-   are self-employed or work in the private sector

# Descriptive statistics

Relevant Numerical Variables:

-   age: Weak positive relationship with stroke (r = 0.24).
-   avg_glucose_level: Very weak positive relationship with stroke (r = 0.13).

Relevant Categorical Variables: - heart_disease - smoking_status - hypertension - ever_married - work_type

Non-Relevant Variables

-   gender: No difference in stroke proportions between female and male categories.
-   residence_type: No difference in stroke proportions across urban and rural categories.
-   bmi: No relationship with stroke (r = 0.04).

## Stroke cases are more frequent at higher glucose levels and in the age range of 60 to 80 years.

```{r, message = FALSE}
#| code-fold: true
#| code-summary: "Click to show code"
library(ggplot2)
library(plotly)

# Function to create the histogram as plotly object
create_histogram <- function(data, variable, stroke_variable, binwidth = 5, show_legend = FALSE) {
  # Extract the variable and stroke data
  original_data <- data[[variable]]
  stroke_data <- data[[stroke_variable]]
  
  # Calculate mean and standard deviation for reference lines
  mean_val <- mean(original_data, na.rm = TRUE)
  sd_val <- sd(original_data, na.rm = TRUE)
  
  # Combine data and stroke status into a data frame
  plot_data <- data.frame(data = original_data, stroke = factor(stroke_data, labels = c("No Stroke", "Stroke")))
  
  # Generate the ggplot object (temporary)
  p <- ggplot(plot_data, aes(x = data, fill = stroke)) +
    geom_histogram(binwidth = binwidth, color = "white", position = "stack") +
    labs(y = "Frequency", fill = "Stroke Status") +
    scale_fill_manual(values = c("No Stroke" = "#1f77b4", "Stroke" = "#ff7f0e")) +  # Set custom colors
    theme_minimal() +
    theme(axis.title.x = element_blank(), plot.title = element_text(hjust = 0.5))  # Center title
  
  # Convert to interactive Plotly plot
  p_plotly <- ggplotly(p) %>%
    layout(showlegend = show_legend)  # Set legend visibility
  
  return(p_plotly)
}

# Generate histograms for each variable separately without repeating legends
hist_age <- create_histogram(outlier_stroke_tb, "age", "stroke", binwidth = 5, show_legend = FALSE) %>%
  layout(title = "Distribution of Age", xaxis = list(title = "Age"), 
         yaxis = list(title = "Frequency"))

hist_glucose <- create_histogram(outlier_stroke_tb, "avg_glucose_level", "stroke", binwidth = 5, show_legend = FALSE) %>%
  layout(title = "Distribution of Average Glucose Level", xaxis = list(title = "Average Glucose Level"), 
         yaxis = list(title = "Frequency"))

hist_bmi <- create_histogram(outlier_stroke_tb, "bmi", "stroke", binwidth = 5, show_legend = FALSE) %>%
  layout(title = "Distribution of BMI", xaxis = list(title = "BMI"), 
         yaxis = list(title = "Frequency"))

# Combine all histograms into a single interactive plot with a main title
combined_histograms <- subplot(hist_age, hist_glucose, hist_bmi, nrows = 1, titleY = TRUE,
                               shareX = TRUE, shareY = TRUE) %>%
  layout(title = "Histograms of Numerical Variables by Stroke", showlegend = TRUE)  # Set main title with legend visible

# Display combined histogram
combined_histograms
```

## There exist weak positive relationships between age and stroke, and avg_glucose_level and stroke. No relationship between bmi and stroke.

```{r, message = FALSE}
#| code-fold: true
#| code-summary: "Click to show code"
library(knitr)

# Calculate correlation coefficients for each variable with stroke
cor_age <- cor(as.numeric(outlier_stroke_tb$age), as.numeric(outlier_stroke_tb$stroke), method = "pearson")
cor_glucose <- cor(as.numeric(outlier_stroke_tb$avg_glucose_level), as.numeric(outlier_stroke_tb$stroke), method = "pearson")
cor_bmi <- cor(as.numeric(outlier_stroke_tb$bmi), as.numeric(outlier_stroke_tb$stroke), method = "pearson")

# Create a correlation table
correlation_table <- data.frame(
  Variable = c("Age", "Average Glucose Level", "BMI"),
  Correlation_with_Stroke = round(c(cor_age, cor_glucose, cor_bmi), 2)
)

# Display the correlation table with kable
kable(correlation_table, caption = "Correlation Coefficients with Stroke")
```

```{r, message = FALSE}
#| code-fold: true
#| code-summary: "Click to show code"
# List of categorical variables
variables_to_summarize <- c("stroke", "gender", "ever_married", "work_type", "Residence_type", "smoking_status", "hypertension", "heart_disease")

# Convert binary integer variables to factors
outlier_stroke_tb <- outlier_stroke_tb %>%
  mutate(
    stroke = as.factor(stroke),
    hypertension = as.factor(hypertension),
    heart_disease = as.factor(heart_disease)
  )

# Calculate total count for proportion calculation
total_count <- nrow(outlier_stroke_tb)

# Create summary table 
summary_table <- bind_rows(
  lapply(variables_to_summarize, function(var) {
    outlier_stroke_tb %>%
      group_by(.data[[var]]) %>%
      summarize(
        Count = n(),
        Proportion = n() / total_count,
        .groups = "drop"
      ) %>%
      rename(Type = .data[[var]]) %>%
      mutate(
        Variable = var,
        Type = as.character(Type),
        Proportion = round(Proportion * 100, 2)  
      )
  })
) %>%
  select(Variable, Type, Count, Proportion) %>%  
  arrange(Variable, Type)                        

# Display the combined table with kable
knitr::kable(summary_table, caption = "Summary of Categorical Variables with Proportion", row.names = FALSE)
```

```{r}
#| code-fold: true
#| code-summary: "Click to show code"

# Define choices for the variable selection, excluding Gender and Residence Type
x_variable_choices <- c("Ever Married" = "ever_married",
                        "Work Type" = "work_type", 
                        "Smoking Status" = "smoking_status",
                        "Hypertension" = "hypertension", 
                        "Heart Disease" = "heart_disease")

# Create a filtered data frame based on all selected variables
filtered_data <- outlier_stroke_tb
# Remove "Other" for the gender variable
filtered_data <- filtered_data %>% filter(!(gender == "Other"))  # Simply check for 'Other' in gender

# Initialize an empty list to store plots
plots <- list()

# Loop through each categorical variable and create a bar chart
for (selected_variable in x_variable_choices) {
  
  # Get variable name
  variable_name <- names(x_variable_choices)[which(x_variable_choices == selected_variable)]
  
  if (variable_name %in% c("hypertension", "heart_disease")) {
    p <- ggplot(filtered_data, aes_string(x = selected_variable, fill = "as.factor(stroke)")) +
      geom_bar(position = "fill") +
      labs(title = paste("Distribution of Stroke by", variable_name),
           fill = "STROKE", y = "Ratio") +
      scale_x_continuous(breaks = c(0, 1), labels = c("No", "Yes")) +  # Custom x-axis for binary variables
      scale_fill_manual(values = c("0" = "#1f77b4", "1" = "#ff7f0e"))  # Set colors for no stroke and stroke
  } else {
    # For other categorical variables
    p <- ggplot(filtered_data, aes_string(x = selected_variable, fill = "as.factor(stroke)")) +
      geom_bar(position = "fill") +
      labs(title = paste("Distribution of Stroke by", variable_name),
           fill = "STROKE", y = "Ratio") +
      scale_fill_manual(values = c("0" = "#1f77b4", "1" = "#ff7f0e"))  # Set colors for no stroke and stroke
  }
  
  # Convert ggplot to an interactive plotly object and store it in the list
  plots[[variable_name]] <- ggplotly(p)
}
# Display all plots
for (plot in plots) {
  print(plot)  # You can use print to display each plot one after the other
}
```

```{r, message = FALSE}
#| code-fold: true
#| code-summary: "Click to show code"
# Select the numeric columns from your data
numeric_data <- outlier_stroke_tb[, c("age", "avg_glucose_level", "bmi")]

# Calculate the correlation matrix
correlation_matrix <- cor(numeric_data, use = "complete.obs")

# Convert the correlation matrix to a format that plotly can use (optional step)
heatmap_data <- as.data.frame(as.table(correlation_matrix))

# Plot the correlation matrix as a heatmap using plotly
plot_ly(
  x = colnames(correlation_matrix),
  y = rownames(correlation_matrix),
  z = correlation_matrix,
  type = "heatmap",
  colorscale = "Viridis"  # Corrected typo
) %>%
  layout(
    title = "Correlation Matrix Heatmap",
    xaxis = list(title = "", tickangle = 45),
    yaxis = list(title = "")
  )
```

# Predictive Modeling

## Final data preparations: 

- Feature Encoding
- Multicollinearity
- Dataset balancing
- Scaling

## Modeling

We divide the analysis into four datasets for model training and evaluation: 
1. Original Dataset 
2. Balanced Original Dataset 
3. Low-Risk Age Group 
4. High-Risk Age Group

Modeling Approach: 
- Train a logistic regression model for each dataset
- Test model performance on a shared test set
-  80% of the data for training and 20% for testing


# Results: 1. Original Dataset

## Baseline Results
![](figures/1_Results.png)
## Baseline Metrics
![](figures/1_Metrics.png)

-   Accuracy: High at 95.08%, but misleading due to poor performance on the minority class (Stroke =Yes).
-   Specificity: Nearly perfect at 99.97%, indicating strong prediction of the majority class (Stroke = No).
-   Recall (Positive Class): Extremely low at 0.5%, identifying very few true positives.
-   F1-Score: Very low at 0.99%, reflecting poor balance between precision and recall.

![](figures/1_ROC.png)
![](figures/1_Odds_ratio.png)
## Interpretation

-   The baseline model is highly biased toward the majority class (Stroke = No).
-   Poor performance on the minority class (Stroke = Yes) makes it unsuitable for predicting strokes effectively.


# Results: 2. Balanced Original Dataset


![](figures/2_Results.png)

## Improved Metrics
![](figures/2_Metrics.png)
-   Accuracy: 77.45% - Strikes a better balance between positive and negative classes.
-   Recall (Positive Class): 81.35% - Effectively identifies most true positives.
-   F1-Score: 78.29% - Indicates a good balance between precision and recall.
-   Specificity: 73.5% - Lower, suggesting some false positives.

![](figures/2_ROC.png)
![](figures/2_Odds_ratio.png)


# Results: 3. Low-Risk Age Group

## Objective: Build the first stratified model for the low-risk age group.

## Approach

-   Dataset Split: Divide the original dataset into training and test sets.
-   Preprocessing: Apply previously mentioned preprocessing steps to the training set.

![](figures/3_Results.png)
![](figures/2_Metrics.png)
![](figures/2_ROC.png)
![](figures/2_Odds_ratio.png)


# Results: 4. High-Risk Age Group

![](figures/4_Results.png)
![](figures/4_Metrics.png)
## Performance Metrics

-   Accuracy: 63.70% - Moderate performance overall.
-   Recall (Positive Class): 66.11% - Captures a fair portion of true positives.
-   Precision: 63.07% - About 63% of predicted positives are correct.
-   F1-Score: 64.56% - Reasonable balance between precision and recall.
-   Specificity: 61.30% - Low, leading to higher false-positive rates.



![](figures/2_ROC.png)
![](figures/2_Odds_ratio.png)
## Interpretation

-   Strength: Moderate ability to capture true positives.
-   Weakness: Struggles to distinguish between classes, with low specificity and accuracy.


# Conclusion


# Grading criteria:

Criteria (Max Points 20): Description

Content (4): Clear and comprehensive explanation of the project, its goals, and outcomes.

Organization (4): Logical flow of information, from introduction to conclusion.

Teamwork (4): Demonstration of collaboration and presentation dynamics (individual projects automatically earn full points).

Visuals (4): Well-designed and relevant slides or visual aids that effectively convey information.

Presentation Mechanics (4): Clear speaking, good video/audio quality, and adherence to time limits.

# Requirements:

Introduction: Briefly introduce your project goals and motivation.

Research Questions: What were the key research questions?

Data: Provide a high-level overview of your data sources and preprocessing.

Findings and Results: Highlight your key findings, insights, or model results.

Conclusion: Summarize your main takeaways and future potential directions.

Length: 7 minutes or less. The time limit will be strictly enforced. Content:

Tell your story well! Focus on delivering clear, concise, and engaging insights from your project. 🚀

# Remarks for presentation slides:

Lets not show results in the presentation that are not relevant. Aim remains to predict stroke.

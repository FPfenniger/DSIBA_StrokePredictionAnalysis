---
title: "_predictive_model"
format: html
---
```{r}
library(caret)
library(tidyverse)
```
# Predictive Model

## Data Preparation for Predictive Modelling 

### Feature Encoding 
For the categorical feature encoding, we convert our categorical variables into dummy variables to utilize them in our predictive model.

```{r, warning=FALSE}
#|code-fold: true
#|code-summary: "Click to show code"
encoded_stroke_tb <- preprocessed_stroke_tb

# Encoding binary categorical variables first
encoded_stroke_tb$ever_married <- ifelse(encoded_stroke_tb$ever_married == "Yes", 1, 0)
encoded_stroke_tb$Residence_type <- ifelse(encoded_stroke_tb$Residence_type == "Urban", 1, 0)
encoded_stroke_tb$gender <- ifelse(encoded_stroke_tb$gender == "Female", 1, 0)

# Create dummy variables for the remaining character columns
to_encode_variables <- names(encoded_stroke_tb)[sapply(encoded_stroke_tb, is.character)]
encoded_stroke_tb <- dummy_cols(
  encoded_stroke_tb, 
  select_columns = to_encode_variables, 
  remove_selected_columns = TRUE
)

# View the final encoded dataset
head(encoded_stroke_tb)
```
To be sure that our model will recognize the binary variables as such, we convert them to factors.
```{r}
#|code-fold: true
#|code-summary: "Click to show code"
# Convert categorical variables to factors
# Ensure proper factor levels for categorical variables
categorical_vars <- c("gender", "ever_married", "Residence_type", "smoking_status_formerly smoked", 
                      "smoking_status_never smoked", "smoking_status_smokes", "stroke", 
                      "hypertension", "heart_disease", "work_type_children", 
                      "work_type_Govt_job", "work_type_Never_worked", "work_type_Private", 
                      "work_type_Self-employed")

# Explicitly convert these columns to factors, and ensure their levels are correct
encoded_stroke_tb[categorical_vars] <- lapply(encoded_stroke_tb[categorical_vars], function(col) {
  if (is.numeric(col)) { # If column is numeric, convert to factor first
    col <- factor(col, levels = unique(col))
  }
  col
})


str(encoded_stroke_tb)

# Save the updated dataset to CSV
write.csv(encoded_stroke_tb, "../../data/datasets/encoded_stroke_tb.csv", row.names = FALSE)

```

### Dataset Balancing

The dataset reveals that most individuals do not have strokes, creating a strong class imbalance. This imbalance can negatively impact model performance by biasing it towards the majority class, resulting in poor predictive accuracy for minority cases like strokes. Without applying upsampling, the model might overly favor "no stroke" predictions, yielding high overall accuracy but failing to identify actual stroke cases effectively (low recall). By upsampling the minority class, we ensure the model learns from stroke cases as well, improving its ability to detect strokes and offering a more balanced and meaningful predictive performance.

```{r, warning=FALSE}
#|code-fold: true
#|code-summary: "Click to show the code"
# Plot the distribution of stroke cases
ggplot(outlier_stroke_tb, aes(x = factor(stroke))) + 
  geom_bar() + 
  labs(x = '0 = No Stroke, 1 = Stroke', y = 'Count', title = 'Distribution of Strokes')

# Count the number of people who had a stroke and calculate the proportion
encoded_stroke_tb %>%
  group_by(stroke) %>%
  summarize(count = n()) %>%
  mutate(proportion = round(count / sum(count), 2))
```
To address this, we used dataset balancing techniques to adjust the proportions of stroke and no-stroke cases. Given that the dataset contains only 5,110 individuals, we chose upsampling the minority class to retain all available data, which would otherwise be reduced through downsampling. By upsampling, we enhance the representation of stroke cases, helping the model learn more effectively and improve both prediction accuracy and recall, particularly for the minority class.

```{r, warning=FALSE}
#|code-fold: true
#|code-summary: "Click to show the code"

# Use upSample to balance the dataset
balanced_stroke_tb <- upSample(
  x = outlier_stroke_tb[, names(outlier_stroke_tb) != "stroke"], # All columns except 'stroke'
  y = outlier_stroke_tb$stroke, # Target variable for upsampling
  yname = "stroke" # Column name for the target variable in the upsampled dataset
)


# Check the structure to confirm changes
str(balanced_stroke_tb)

# Check the distribution to confirm balancing
table(balanced_stroke_tb$stroke)

# Save the dataset
write.csv(balanced_stroke_tb, "../../data/datasets/balanced_stroke_tb.csv", row.names = FALSE)

```

### Feature scaling

Finally, as classification algorithms are often sensitive to scales and to prevent perturbations, we standardize all continuous features in the dataset.
```{r, warning=FALSE}
#|code-fold: true
#|code-summary: "Click to show code"

scaled_stroke_tb <- balanced_stroke_tb

scaled_unbalanced_stroke_tb <- outlier_stroke_tb

#Scale only the double columns

scaled_stroke_tb[sapply(scaled_stroke_tb, is.double)] <- lapply(scaled_stroke_tb[sapply(scaled_stroke_tb, is.double)], scale)

scaled_stroke_tb <- as_tibble(scaled_stroke_tb)

head(scaled_stroke_tb)


scaled_unbalanced_stroke_tb[sapply(scaled_unbalanced_stroke_tb, is.double)] <- lapply(scaled_unbalanced_stroke_tb[sapply(scaled_unbalanced_stroke_tb, is.double)], scale)

scaled_unbalanced_stroke_tb <- as_tibble(scaled_unbalanced_stroke_tb)

# save
write.csv(scaled_stroke_tb, "../../data/datasets/scaled_stroke_tb.csv", row.names = FALSE)
write.csv(scaled_unbalanced_stroke_tb, "../../data/datasets/scaled_unbalanced_stroke_tb.csv", row.names = FALSE)
```

## Baseline Model
First of all, we set a seed to guarantee reproducibility of the results in the next chapter.

```{r}
set.seed(42)
```

We divide our analysis into four different datasets and predictive models: the original dataset, the balanced original dataset, the low-risk age group, and the moderate-risk age group. We will train a logistic regression model for each dataset, before evaluating them on the test sets in the next chapter and comparing them to the baseline model.

### Train-test split

In order to evaluate the performance of our model, we split the original dataset into a training and a test set. We use 80% of the data for training and 20% for testing.
```{r}
# Load the dataset
unbalanced_original_data <- read.csv("../../data/datasets/scaled_unbalanced_stroke_tb.csv")
str(unbalanced_original_data)
```

```{r}
categorical_variables <- names(unbalanced_original_data)[sapply(unbalanced_original_data, function (x) is.integer(x))]

unbalanced_original_data[categorical_variables] <- lapply(unbalanced_original_data[categorical_variables], factor)

str(unbalanced_original_data)
```

```{r}
unbalanced_original_data[categorical_variables] <- lapply(unbalanced_original_data[categorical_variables], function(col) {
  levels(col) <- make.names(levels(col))  # Ensure valid names for all levels
  return(col)
})
```

```{r}
# Split into training (80%) and testing (20%) sets
set.seed(42)  
trainIndex <- createDataPartition(unbalanced_original_data$stroke, p = 0.8, 
                                  list = FALSE, times = 1)

train_unbalanced <- unbalanced_original_data[trainIndex, ]
test_unbalanced <- unbalanced_original_data[-trainIndex, ]
```

### Model 
We use k-fold cross validation to train and evaluate our model. 

```{r}
# Set up k-fold cross-validation (e.g., 5 folds)
k <- 5
ctrl <- trainControl(method = "cv", number = k, 
                     classProbs = TRUE,  
                     summaryFunction = twoClassSummary)  

# Train a logistic regression model using k-fold CV
set.seed(42)  
logistic_model_1 <- train(stroke ~ ., data = train_unbalanced,
                          method = "glm", family = "binomial",
                          trControl = ctrl, metric = "ROC") 

# Print cross-validation results
print(logistic_model_1)
```
## Balanced Baseline Model

### Train-test split
```{r}
# Load the dataset
balanced_original_data <- read.csv("../../data/datasets/scaled_stroke_tb.csv")
```

```{r}
categorical_variables <- names(balanced_original_data)[sapply(balanced_original_data, function (x) is.integer(x))]

balanced_original_data[categorical_variables] <- lapply(balanced_original_data[categorical_variables], factor)

str(balanced_original_data)
```

```{r}
balanced_original_data[categorical_variables] <- lapply(balanced_original_data[categorical_variables], function(col) {
  levels(col) <- make.names(levels(col))  # Ensure valid names for all levels
  return(col)
})
```

```{r}
# Split into training (80%) and testing (20%) sets
set.seed(42)  
trainIndex <- createDataPartition(balanced_original_data$stroke, p = 0.8, 
                                  list = FALSE, times = 1)

train_balanced <- balanced_original_data[trainIndex, ]
test_balanced <- balanced_original_data[-trainIndex, ]
```

### Model
```{r}
k <- 5
ctrl <- trainControl(method = "cv", number = k, 
                     classProbs = TRUE,  # Enables ROC computation
                     summaryFunction = twoClassSummary)  # Use ROC as metric

# Train a logistic regression model using k-fold CV
set.seed(42)  
logistic_model_2 <- train(stroke ~ ., data = train_balanced,
                          method = "glm", family = "binomial",
                          trControl = ctrl, metric = "ROC")

# Print cross-validation results
print(logistic_model_2)
```


## Low-Risk Age Model

### Train-test split
```{r}
# Load the dataset
low_risk_age_data <- read.csv("../../data/datasets/low_risk_age_tb.csv")
str(low_risk_age_data)
```

```{r}
categorical_variables <- names(low_risk_age_data)[sapply(low_risk_age_data, function (x) is.integer(x))]

balanced_original_data[low_risk_age_data] <- lapply(low_risk_age_data[categorical_variables], factor)

str(low_risk_age_data)
```

```{r}
low_risk_age_data[categorical_variables] <- lapply(low_risk_age_data[categorical_variables], function(col) {
  levels(col) <- make.names(levels(col))  # Ensure valid names for all levels
  return(col)
})
```

```{r}
# Split into training (80%) and testing (20%) sets
set.seed(42)  
trainIndex <- createDataPartition(low_risk_age_data$stroke, p = 0.8, 
                                  list = FALSE, times = 1)

train_low_age <- low_risk_age_data[trainIndex, ]
test_low_age <- low_risk_age_data[-trainIndex, ]

# Check for missing values
colSums(is.na(balanced_original_data))

```



### Model
```{r}
k <- 5
ctrl <- trainControl(method = "cv", number = k, 
                     classProbs = TRUE,  # Enables ROC computation
                     summaryFunction = twoClassSummary)  # Use ROC as metric

# Train a logistic regression model using k-fold CV
set.seed(42)  
logistic_model_3 <- train(stroke ~ ., data = train_low_age,
                          method = "glm", family = "binomial",
                          trControl = ctrl, metric = "ROC")

# Print cross-validation results
print(logistic_model_3)
```

## Moderate-Risk Age Model

### Train-test split
```{r}
# Load the dataset
moderate_risk_age_data <- read.csv("../../data/datasets/scaled_stroke_tb.csv")
```

```{r}
categorical_variables <- names(moderate_risk_age_data)[sapply(moderate_risk_age_data, function (x) is.integer(x))]

moderate_risk_age_data[categorical_variables] <- lapply(moderate_risk_age_data[categorical_variables], factor)

str(moderate_risk_age_data)
```

```{r}
moderate_risk_age_data[categorical_variables] <- lapply(moderate_risk_age_data[categorical_variables], function(col) {
  levels(col) <- make.names(levels(col))  # Ensure valid names for all levels
  return(col)
})
```

```{r}
# Split into training (80%) and testing (20%) sets
set.seed(42)  
trainIndex <- createDataPartitionmoderate_risk_age_data$stroke, p = 0.8, 
                                  list = FALSE, times = 1)

train_moderate_age <- moderate_risk_age_data[trainIndex, ]
test_moderate_age <- moderate_risk_age_data[-trainIndex, ]

# Check for missing values
colSums(is.na(moderate_risk_age_data))

```

### Model
```{r}
k <- 5
ctrl <- trainControl(method = "cv", number = k, 
                     classProbs = TRUE,  # Enables ROC computation
                     summaryFunction = twoClassSummary)  # Use ROC as metric

# Train a logistic regression model using k-fold CV
set.seed(42)  
logistic_model_4 <- train(stroke ~ ., data = train_moderate_age,
                          method = "glm", family = "binomial",
                          trControl = ctrl, metric = "ROC")

# Print cross-validation results
print(logistic_model_4)
``` 

---
title: "_predictive_model"
format: html
editor: 
  markdown: 
    wrap: 72
---

```{r}
library(caret)
library(tidyverse)
library(vcd)
library(knitr)
library(fastDummies)
library(janitor)
```

# Predictive Model

## Final Data Preparations

```{r, message = FALSE}
#| code-fold: true
#| code-summary: "Click to show code"
outlier_stroke_tb <- read.csv("../../data/datasets/outlier_stroke_tb.csv")
```



### Feature Encoding

For the categorical feature encoding, we convert our categorical
variables into dummy variables to utilize them in our predictive model.

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"
encoded_stroke_tb <- outlier_stroke_tb

# Encoding binary categorical variables first
encoded_stroke_tb$ever_married <- ifelse(encoded_stroke_tb$ever_married == "Yes", 1, 0)
encoded_stroke_tb$Residence_type <- ifelse(encoded_stroke_tb$Residence_type == "Urban", 1, 0)
encoded_stroke_tb$gender <- ifelse(encoded_stroke_tb$gender == "Female", 1, 0)

# Create dummy variables for the remaining character columns
to_encode_variables <- names(encoded_stroke_tb)[sapply(encoded_stroke_tb, is.character)]
encoded_stroke_tb <- dummy_cols(
  encoded_stroke_tb, 
  select_columns = to_encode_variables, 
  remove_selected_columns = TRUE
)
# Clean names
encoded_stroke_tb <- clean_names(encoded_stroke_tb)

# View the final encoded dataset
kable(encoded_stroke_tb)
```

To be sure that our model will recognize the binary variables as such,
we convert them to factors.

```{r}
#| code-fold: true
#| code-summary: "Click to show code"
# Convert categorical variables to factors
# Ensure proper factor levels for categorical variables
categorical_vars <- c("gender", "ever_married", "residence_type", "smoking_status_formerly_smoked", 
                      "smoking_status_never_smoked", "smoking_status_smokes", 
                      "hypertension", "heart_disease", "work_type_children", 
                      "work_type_govt_job", "work_type_private", 
                      "work_type_self_employed", "stroke")

# Explicitly convert these columns to factors, and ensure their levels are correct
encoded_stroke_tb[categorical_vars] <- lapply(encoded_stroke_tb[categorical_vars], function(col) {
  if (is.numeric(col)) { # If column is numeric, convert to factor first
    col <- factor(col, levels = unique(col))
  }
  col
})

colnames(encoded_stroke_tb) <- make.names(colnames(encoded_stroke_tb))

str(encoded_stroke_tb)

# Save the updated dataset to CSV
write.csv(encoded_stroke_tb, "../../data/datasets/encoded_stroke_tb.csv", row.names = FALSE)

```
### Multicollinearity

To examine associations and multicollinearity between the categorical
variables, we use a chi-squared test. The chi-squared test is a
statistical test used to determine whether there is a significant
association between two categorical variables. To determine the
importance of the test result we additionally computed the Cramér's V
for effect size (threshold applied here 0.3). Additionally, we apply the Fisher's Exact Test if there are
zero counts in the contingency table.

```{r, message = FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

cat_variables = c("gender", "ever_married", "residence_type", "smoking_status_formerly_smoked", 
                      "smoking_status_never_smoked", "smoking_status_smokes", 
                      "hypertension", "heart_disease", "work_type_children", 
                      "work_type_govt_job", "work_type_private", 
                      "work_type_self_employed")

for (index1 in 1:(length(cat_variables) - 1)) {
  var1 <- cat_variables[index1]
  
  for (index2 in (index1 + 1):length(cat_variables)) {
    var2 <- cat_variables[index2]
    
    contingency_table <- table(encoded_stroke_tb[[var1]], encoded_stroke_tb[[var2]])
    
    # Run Fisher's Exact Test if there are zero counts, otherwise Chi-square Test
    if (any(contingency_table == 0)) {
      chi_square_result <- fisher.test(contingency_table, simulate.p.value = TRUE)
    } else {
      chi_square_result <- chisq.test(contingency_table)
    }
    
    cramers_v <- assocstats(contingency_table)$cramer
    
    if (cramers_v > 0.3 && chi_square_result$p.value < 0.05) {
      cat("Relationship between", var1, "and", var2, "\n")
      cat("P-value:", chi_square_result$p.value, "\n")
      cat("Cramér's V:", cramers_v, "\n")
      print(contingency_table)
      cat("\n")
    }
  }
}
```

The only relationship, which seems to be problematic in terms of
multicollinearity seems to be between `ever_married` and `work_type`.
For the prediction model, we will therefore exclude one of the two
features. Another possibility is to further explore their relationship
with the VIF(Variation Inflation Factor), which will help us with the
decision to either keep both variables or drop one of them.

As all other effect sizes appear to be smaller than 0.3, we can safely
conclude that all other categorical features are sufficiently
independent to use as predictors. In conclusion, multicollinearity does
not appear to be present among the variables, and we can therefore
proceed. The correlation matrix in the previous chapter indicated low
correlations between features as well. We therefore refrain from
conducting a multivariate analysis, as the results from this section
seem robust enough to also conclude no multicollinearity among multiple
features.

### Dataset Balancing

The dataset revealed that most individuals do not have strokes, creating
a strong class imbalance. This imbalance can negatively impact model
performance by biasing it towards the majority class, resulting in poor
predictive accuracy for minority cases like strokes. Without applying
upsampling, the model might overly favor "no stroke" predictions,
yielding high overall accuracy but failing to identify actual stroke
cases effectively (low recall). By upsampling the minority class, we
ensure the model learns from stroke cases as well, improving its ability
to detect strokes and offering a more balanced and meaningful predictive
performance.

Let's start by creating the two stratified datasets, where we take the age of 60 to split our sample in two groups. As seen in our EDA, individuals aged over 60 have a significantly higher risk of stroke. 
```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show the code"

low_risk_age_tb <- encoded_stroke_tb %>%
  filter(age < 60)

high_risk_age_tb <- encoded_stroke_tb %>%
  filter(age >= 60)
```

Let's look at stroke occurrences in our three datasets:
```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show the code"

# Count the number of people who had a stroke and calculate the proportion
encoded_stroke_tb %>%
  group_by(stroke) %>%
  summarize(count = n()) %>%
  mutate(proportion = round(count / sum(count), 2))

low_risk_age_tb %>%
  group_by(stroke) %>%
  summarize(count = n()) %>%
  mutate(proportion = round(count / sum(count), 2))

high_risk_age_tb %>%
  group_by(stroke) %>%
  summarize(count = n()) %>%
  mutate(proportion = round(count / sum(count), 2))


```

To address this issue, we use dataset balancing techniques to adjust the
proportions of stroke and no-stroke cases. Given that the dataset
contains only 5,110 individuals, we chose upsampling the minority class
to retain all available data, which would otherwise be reduced through
downsampling. By upsampling, we enhance the representation of stroke
cases, helping the model learn more effectively and improve both
prediction accuracy and recall, particularly for the minority class
(here when strokes occur).

```{r, warning=FALSE}
#|code-fold: true
#|code-summary: "Click to show the code"

# Use upSample to balance the dataset
balanced_stroke_tb <- upSample(
  x = encoded_stroke_tb[, names(encoded_stroke_tb) != "stroke"], 
  y = encoded_stroke_tb$stroke, 
  yname = "stroke"
)

low_risk_age_data <- upSample(
  x = low_risk_age_tb[, names(low_risk_age_tb) != "stroke"], 
  y = low_risk_age_tb$stroke, 
  yname = "stroke"
)

high_risk_age_data <- upSample(
  x = high_risk_age_tb[, names(high_risk_age_tb) != "stroke"], 
  y = high_risk_age_tb$stroke, 
  yname = "stroke"
)


# Check the structure to confirm changes
str(balanced_stroke_tb)


# Check the distribution to confirm balancing
table(balanced_stroke_tb$stroke)
table(low_risk_age_data$stroke)

# Save the dataset
write.csv(balanced_stroke_tb, "../../data/datasets/balanced_stroke_tb.csv", row.names = FALSE)
```
Because the upsampling in the low-risk age group is rather extreme (from 1.5% to 50% stroke cases), we will use the upsampled dataset only for training and use the original dataset for the evaluation. 

Finally, as classification algorithms are often sensitive to feature scales, we standardize all continuous features in the dataset to prevent perturbations and improve model performance. Standardization rescales features to have a mean of 0 and a standard deviation of 1. The mathematical formula for standardization is as follows:

$$
z = \frac{x - \mu}{\sigma}
$$

Where:
-   z is the standardized value,
-   x is the original feature value,
-   ( \mu ) is the mean of the feature,
-   ( \sigma ) is the standard deviation of the feature.


```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

# Define a function to standardize continuous variables
standardize <- function(x) {
  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
}

# Apply standardization to continuous (numeric) columns in the dataset
scaled_stroke_tb <- balanced_stroke_tb %>%
  mutate(across(where(is.double), ~ standardize(.)))

scaled_unbalanced_stroke_tb <- encoded_stroke_tb %>%
  mutate(across(where(is.double), ~ standardize(.)))

scaled_low_risk_age_tb <- low_risk_age_data %>%
  mutate(across(where(is.double), ~ standardize(.)))

scaled_high_risk_age_tb <- high_risk_age_data %>%
  mutate(across(where(is.double), ~ standardize(.)))

# Display the scaled dataset
kable(scaled_stroke_tb)

# Save the scaled datasets
write.csv(scaled_stroke_tb, "../../data/datasets/scaled_stroke_tb.csv", row.names = FALSE)
write.csv(scaled_unbalanced_stroke_tb, "../../data/datasets/scaled_unbalanced_stroke_tb.csv", row.names = FALSE)
write.csv(scaled_low_risk_age_tb, "../../data/datasets/scaled_low_risk_age_tb.csv", row.names = FALSE)
write.csv(scaled_high_risk_age_tb, "../../data/datasets/scaled_high_risk_age_tb.csv", row.names = FALSE)
```

## Baseline Model

We divide our analysis into four different datasets and predictive
models: the original dataset, the balanced original dataset, the
low-risk age group, and the moderate-risk age group. We will train a
logistic regression model for each dataset, before evaluating them on
the test sets in the next chapter and comparing them to the baseline
model.

### Train-test split

In order to evaluate the performance of our model, we split the original
dataset into a training and a test set. We use 80% of the data for
training and 20% for testing.

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"
# Load the dataset
unbalanced_original_data <- scaled_unbalanced_stroke_tb
str(unbalanced_original_data)
```
```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

# Ensure valid names for all levels
unbalanced_original_data[categorical_variables] <- lapply(unbalanced_original_data[categorical_variables], function(col) {
  levels(col) <- make.names(levels(col)) 
  return(col)
})
```

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"
# Split into training (80%) and testing (20%) sets
set.seed(42)  
trainIndex <- createDataPartition(unbalanced_original_data$stroke, p = 0.8, 
                                  list = FALSE, times = 1)

train_unbalanced <- unbalanced_original_data[trainIndex, ]
test_unbalanced <- unbalanced_original_data[-trainIndex, ]

```

### Model

We use k-fold cross validation to train and evaluate our model. With the `caret` package, we specify our first logistic model by specifying (method= "glm") and (family = "binomial") to train a logistic regression model.

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

# Custom summary function for Precision, Recall, and ROC AUC
custom_summary <- function(data, lev = NULL, model = NULL) {
  precision <- tryCatch(posPredValue(data$pred, data$obs, positive = lev[1]), error = function(e) NA)
  recall <- tryCatch(sensitivity(data$pred, data$obs, positive = lev[1]), error = function(e) NA)
  roc_auc <- tryCatch(pROC::roc(data$obs, data[, lev[1]])$auc, error = function(e) NA)
  c(Precision = precision, Recall = recall, ROC = roc_auc)
}

# Train 
ctrl <- trainControl(
  method = "none",    
  classProbs = TRUE   # Enable class probabilities
)

# Train logistic regression model on the entire training dataset
set.seed(42)
logistic_model_1 <- train(
  stroke ~ ., 
  data = train_unbalanced,
  method = "glm",
  family = "binomial",
  trControl = ctrl,
  metric = "ROC"
)

# Print model summary
summary(logistic_model_1)

```

## Balanced Baseline Model

### Train-test split

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

# Load the dataset
balanced_original_data <- scaled_stroke_tb
```

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

# Ensure valid names for all levels
balanced_original_data[categorical_variables] <- lapply(balanced_original_data[categorical_variables], function(col) {
  levels(col) <- make.names(levels(col))  
  return(col)
})
```

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

# Split into training (80%) and testing (20%) sets
set.seed(42)  
trainIndex <- createDataPartition(balanced_original_data$stroke, p = 0.8, 
                                  list = FALSE, times = 1)

train_balanced <- balanced_original_data[trainIndex, ]
test_balanced <- balanced_original_data[-trainIndex, ]
```

### Model

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

k <- 5
ctrl <- trainControl(method = "cv", number = k, 
                     classProbs = TRUE,  # Enables ROC computation
                     summaryFunction = twoClassSummary)  # Use ROC as metric

# Train a logistic regression model using k-fold CV
set.seed(42)  
logistic_model_2 <- train(stroke ~ ., data = train_balanced,
                          method = "glm", family = "binomial",
                          trControl = ctrl, metric = "ROC")

# Print cross-validation results
print(logistic_model_2)
```

## Low-Risk Age Model

### Train-test split

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

# Load the dataset
low_risk_age_data <- read.csv("../../data/datasets/low_risk_age_tb.csv")
str(low_risk_age_data)
```

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

categorical_variables <- names(low_risk_age_data)[sapply(low_risk_age_data, function (x) is.integer(x))]

balanced_original_data[low_risk_age_data] <- lapply(low_risk_age_data[categorical_variables], factor)

str(low_risk_age_data)
```

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

low_risk_age_data[categorical_variables] <- lapply(low_risk_age_data[categorical_variables], function(col) {
  levels(col) <- make.names(levels(col))  # Ensure valid names for all levels
  return(col)
})
```

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

# Split into training (80%) and testing (20%) sets
set.seed(42)  
trainIndex <- createDataPartition(low_risk_age_data$stroke, p = 0.8, 
                                  list = FALSE, times = 1)

train_low_age <- low_risk_age_data[trainIndex, ]
test_low_age <- low_risk_age_data[-trainIndex, ]

# Check for missing values
colSums(is.na(balanced_original_data))

```

### Model

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

k <- 5
ctrl <- trainControl(method = "cv", number = k, 
                     classProbs = TRUE,  # Enables ROC computation
                     summaryFunction = twoClassSummary)  # Use ROC as metric

# Train a logistic regression model using k-fold CV
set.seed(42)  
logistic_model_3 <- train(stroke ~ ., data = train_low_age,
                          method = "glm", family = "binomial",
                          trControl = ctrl, metric = "ROC")

# Print cross-validation results
print(logistic_model_3)
```

## Moderate-Risk Age Model

### Train-test split

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

# Load the dataset
moderate_risk_age_data <- read.csv("../../data/datasets/scaled_stroke_tb.csv")
```

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

categorical_variables <- names(moderate_risk_age_data)[sapply(moderate_risk_age_data, function (x) is.integer(x))]

moderate_risk_age_data[categorical_variables] <- lapply(moderate_risk_age_data[categorical_variables], factor)

str(moderate_risk_age_data)
```

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

moderate_risk_age_data[categorical_variables] <- lapply(moderate_risk_age_data[categorical_variables], function(col) {
  levels(col) <- make.names(levels(col))  # Ensure valid names for all levels
  return(col)
})
```

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

# Split into training (80%) and testing (20%) sets
set.seed(42)  
trainIndex <- createDataPartitionmoderate_risk_age_data$stroke, p = 0.8, 
                                  list = FALSE, times = 1)

train_moderate_age <- moderate_risk_age_data[trainIndex, ]
test_moderate_age <- moderate_risk_age_data[-trainIndex, ]

# Check for missing values
colSums(is.na(moderate_risk_age_data))

```

### Model

```{r, warning=FALSE}
#| code-fold: true
#| code-summary: "Click to show code"

k <- 5
ctrl <- trainControl(method = "cv", number = k, 
                     classProbs = TRUE,  # Enables ROC computation
                     summaryFunction = twoClassSummary)  # Use ROC as metric

# Train a logistic regression model using k-fold CV
set.seed(42)  
logistic_model_4 <- train(stroke ~ ., data = train_moderate_age,
                          method = "glm", family = "binomial",
                          trControl = ctrl, metric = "ROC")

# Print cross-validation results
print(logistic_model_4)
```
